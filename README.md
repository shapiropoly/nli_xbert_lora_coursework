# Multilingual logical relation classifier mBERT + LORA

Каталог space_app является подмодулем — полный код Space лежит на Hugging Face»

Репозиторий на Hugging Face Spaces:  
▶ **https://huggingface.co/spaces/shapiropoly/coursework_nli_xlmr_lora**


## Состав репозитория

| Каталог / файл    | Содержание                                                                                                                                   |
|-------------------|----------------------------------------------------------------------------------------------------------------------------------------------|
| **`space_app/`**  | Git-подмодуль с кодом Streamlit-приложения; открывает HF Space (см. выше).                                                                   |
| **`notebooks/`**  | Jupyter-ноутбуки:<br>• `01_baseline.ipynb` — воспроизведение полного fine-tune mBERT<br>• `02_lora_training.ipynb` — обучение LoRA-адаптера  |
| **`report/`**     | Курсовая и PDF итогового отчёта.                                                                                                             |
| **`figures/`**    | t-SNE, heat-maps и другие рисунки, на которые ссылается отчёт.                                                                               |
| **`.gitmodules`** | указывает, что `space_app/` — подмодуль, привязанный к HF-репозиторию.                                                                       |



Репозиторий на Hugging Face содержит компактную версию **mBERT-base**, дообученную методом **Low-Rank Adaptation** (LoRA) на датасете Kaggle *“Contradictory, My Dear Watson”*.  
Модель классифицирует логическую связь между двумя предложениями (*premise*, *hypothesis*) и выдаёт одну из трёх меток:

| label id | метка             | описание                                  |
|---------:|-------------------|-------------------------------------------|
| 0        | **Entailment**    | гипотеза логически следует из посылки     |
| 1        | **Neutral**       | отношения нет                             |
| 2        | **Contradiction** | гипотеза противоречит посылке             |

LoRA-адаптер увеличил количество обучаемых весов всего на **0,6 %**, поэтому итоговый чек-пойнт весит ≈ 420 МБ и работает даже на CPU-инстансах.


## Быстрый тест в браузере

Попробовать модель можно на Hugging Face Spaces:  
▶ **https://huggingface.co/spaces/shapiropoly/coursework_nli_xlmr_lora**


Инструкция как пользоваться демо:

1. Введите два предложения: предпосылку и гипотезу, нажмите "Check"
2. Если хотите посмотреть тепловую карту по токенам, выберите 
"Show attention heat-map" — так вы увидите, на какие слова модель 
больше обращает внимание при принятии решения

## Детали модели

| характеристика           | значение                         |
|--------------------------|----------------------------------|
| базовая архитектура      | mBERT-base, 12×768, 110 M params |
| LoRA-ранг                | `r = 16`, `α = 16`               |
| модифицированные проекции| `query`, `value`                 |
| обучаемых параметров     | **≈ 0,6 %** от полного fine-tune |
| макс. длина токенов      | 512                              |
| языки предобучения       | 104 (Wiki dump)                  |